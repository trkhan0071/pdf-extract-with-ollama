# ğŸ“„ PDF â†’ SQLite â†’ LLM Pipeline

A simple document processing pipeline in Python:

1. **Ingestion** â†’ Read PDFs from a folder  
2. **Processing** â†’ Normalize + chunk text  
3. **Storage** â†’ Save chunks into SQLite  
4. **Query** â†’ Retrieve relevant chunks and pass them to an LLM (via [Ollama](https://ollama.com/))  

---

## ğŸ“‚ Project Structure

pdf_pipeline/
â”œâ”€â”€ data/ # ğŸ“¥ put your PDFs here
â”‚ â”œâ”€â”€ sample1.pdf
â”‚ â””â”€â”€ sample2.pdf
â”œâ”€â”€ db/ # ğŸ“¦ SQLite database (auto-created)
â”œâ”€â”€ pdf_pipeline/ # ğŸ”§ source code
â”‚ â”œâ”€â”€ ingestion.py # PDF ingestion
â”‚ â”œâ”€â”€ processing.py # text cleaning + chunking
â”‚ â”œâ”€â”€ storage.py # SQLite storage
â”‚ â”œâ”€â”€ query.py # query interface + LLM call
â”‚ â””â”€â”€ utils.py # helper functions
â”œâ”€â”€ main.py # CLI entry point
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # this file

yaml
Copy code

---

## âš™ï¸ Setup

### 1. Clone the repo
```bash
git clone <your-repo-url>
cd pdf_pipeline
2. Create a virtual environment
bash
Copy code
python3 -m venv venv
source venv/bin/activate   # Linux / macOS
venv\Scripts\activate      # Windows
3. Install Python dependencies
bash
Copy code
pip install -r requirements.txt
4. Install Ollama (system-wide, not in venv)
Windows â†’ Download installer

macOS â†’

bash
Copy code
brew install ollama/tap/ollama
Linux â†’

bash
Copy code
curl -fsSL https://ollama.com/install.sh | sh
Verify installation:

bash
Copy code
ollama --version
5. Pull a model
bash
Copy code
ollama pull llama2
ğŸš€ Usage
1. Add PDFs
Place your PDFs in the data/ folder. Example:

bash
Copy code
data/report1.pdf
data/report2.pdf
2. Ingest PDFs
bash
Copy code
python main.py ingest data/
This will:

Extract text from each PDF

Normalize + chunk the text

Store chunks in db/chunks.db

Example output:

diff
Copy code
==================== Ingestion ====================

Ingested report1.pdf (12 chunks)
Ingested report2.pdf (20 chunks)
3. Query the database
bash
Copy code
python main.py query "What is the main conclusion of the report?"
Example output:

diff
Copy code
==================== Query ====================

Answer:
The report concludes that...
ğŸ› ï¸ Troubleshooting
'ollama' is not recognized â†’ Install Ollama system-wide (see Setup step 4) and restart your terminal.

ImportError: attempted relative import â†’ Use absolute imports in main.py or run as a module:

bash
Copy code
python -m main ingest data/
Database not found â†’ Run ingestion first (python main.py ingest data/).

ğŸ“Œ Notes
Storage uses simple keyword search (LIKE) for chunk retrieval.

For better accuracy, you can extend this with embeddings + semantic search (e.g., sentence-transformers + FAISS).

This project is a starting point â€” extend as needed for production.
